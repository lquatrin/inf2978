import timeimport mathimport randomimport bwreadersimport bwdistanceimport bwnumbergenimport bwserializationimport bwprojectionimport bwmathimport numpy as npimport osimport gcimport bwrunsimport svddocsprojectionfrom scipy.spatial.distance import pdistmy_out_path = ''# QtTecgraf#my_out_path = 'C:/Users/lquatrin/Dropbox/data/'# QtHome#my_out_path = 'E:/Dropbox/data/home/'output_path = my_out_pathDOCWORD_FILE = "../docword.nytimes.txt"VOCAB_FILE = "vocab.nytimes.txt"# 1 2# 1. Baixe o dataset Bag of Words da UCI (arquivo NyTimes). Cerca de 300k docs e vocabulario com 102650 termos# 2. Crie uma bag of words para os 3000 primeiros documentosword_list = bwreaders.ReadVocabulary(VOCAB_FILE)D_t_work = 3000table_docs = bwreaders.ReadDocuments(DOCWORD_FILE, D_t_work)#documents =  bwreaders.read_document_corpus(filepath= './docword.nytimes.txt_preprocessed.txt',#                                              num_docs=3000,#                                              num_words_in_vocabulary=102650)documents = table_docs[0]# n documentosD = table_docs[1]# n palavrasW = table_docs[2]# n entradasNNZ = table_docs[3]# 3# 3. Calcule a distancia entre cada par de pontos atraves da forca bruta e messa o tempo computacional deste procedimento. Armazene estes valores. Utilize dois loops para fazer isso e implemente o calculo da distanciamtx_original_distance = bwdistance.GenerateOriginalDistanceMatrix(D_t_work, W, documents)# Create DataDocsdata_doc = np.zeros(shape = (W, D_t_work))for doc_id in range(D_t_work):  for word_id, count_w in documents[doc_id].items():    data_doc[word_id, doc_id] = float(count_w)documents = data_doc# Transform into a distance array distance_array = np.zeros(shape = (int(D_t_work*(D_t_work - 1)*0.5)))ind = 0for x in range(D_t_work):  for y in range(x+ 1, D_t_work):    distance_array[ind] = mtx_original_distance[x][y]    ind += 1# 4# 4. Para n = 4, 16, 64, 256, 1024, 4096, 15768, repita o procedimento abaixo 30 vezesrepeat = 30n_cases = [ ]#4, 16, 64, 256, 1024, 4096, 15768 ]for N_case in n_cases:  # 4.6  #text_file = open(my_out_path + str(N_case) + "_JL.txt", "w")  #text_file.write("%f" % (bwmath.CalculateJLLema(D_t_work, N_case)))  #text_file.close()    ####################################################################  # Versão 1:  # - Geração da matriz   # - Projeção (maior consumo de memória)  ####################################################################  bwruns.RunVersion01(documents, mtx_original_distance, N_case, repeat, W, D_t_work, output_path, False, True)  ####################################################################  # Versão 2:  # - Geração e projeção ao mesmo tempo (menor consumo de memória)  ####################################################################  #bwruns.RunVersion02(documents, mtx_original_distance, N_case, repeat, W, D_t_work, output_path, True, True)#https://www.cs.cmu.edu/~venkatg/teaching/CStheory-infoage/book-chapter-4.pdf#https://pdfs.semanticscholar.org/4dd0/146ae1d403aba8d0774315f4e2386948034f.pdf#http://www.dt.fee.unicamp.br/~ivanil/adaptive_svd_encoder-analise_metodo_wei.pdf#http://www.geometrie.tugraz.at/sgp2015/slides/3a_Mapping_Poranne/Mappings_partA.pdf#http://bud.cs.uky.edu/~jzhang/pub/PRINT/xu6.pdf#https://en.wikipedia.org/wiki/Singular_value_decomposition#http://web.mit.edu/be.400/www/SVD/Singular_Value_Decomposition.htmtext_errr_file = open(output_path + "svd_tests_erro.txt", "w")text_time_file = open(output_path + "svd_tests_time.txt", "w")text_errr_file.write("%s\t%s\t%s\t%s\t%s\n" % ('N', 'Quality_1', 'Quality_2', 'Frobenius', 'MaxError'))text_time_file.write("%s\t%s\t%s\t%s\t%s\t%s\t%s\n" % ('N', 'SVD_Time', 'Reconstruction', 'EspectralNorm2', 'TimeQuality1', 'TimeSingularQuality', 'MaxError'))svd_cases = [ ]#4, 16, 64, 256 ]for N_svd_case in svd_cases:  ####################################################################  # Versão 3:  # - SVD  ####################################################################  rep = svddocsprojection.SVDDocsProjection(documents, distance_array, N_svd_case, W, D_t_work, output_path)    text_errr_file.write("%d\t%f\t%f\t%f\t%f\n" % (N_svd_case, rep['q1'], rep['q2'], rep['espectralnorm'], rep['maxerr']))  text_time_file.write("%d\t%f\t%f\t%f\t%f\t%f\t%f\n" % (N_svd_case, rep['svdtime'], rep['akbuildtime'], rep['time_espectralnorm'], rep['time_q1'], rep['time_q2'], rep['time_maxerr']))text_errr_file.close()text_time_file.close()